{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist = tf.keras.datasets.mnist\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# alpha = 0.1;\n",
    "# trainingId = 0;\n",
    "\n",
    "# def sigmoid(x):\n",
    "#     return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "# X = x_train[trainingId].reshape(-1,1)\n",
    "# Y = np.empty((10, 1));\n",
    "# W3 = np.random.rand(Y.size, X.size);\n",
    "# B3 = np.random.rand(Y.size, 1);\n",
    "# A3 = W3 @ X + B3;\n",
    "# Y = sigmoid(A3);\n",
    "# correctY = np.zeros((Y.size,1));\n",
    "# correctY[y_train[trainingId]] = 1;\n",
    "# dY = correctY - Y;\n",
    "# dW3 = 2/Y.size * W3 * dY * X.T;\n",
    "# W3 = W3 * alpha * dW3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rng\n",
    "# Load dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "data = mnist.load_data()\n",
    "# Split into train set and test set\n",
    "train = data[0]\n",
    "test = data[1]\n",
    "# Getting array containing dataset matrices with actual pixel values (each 28 x 28)\n",
    "x_train = train[0]\n",
    "x_test = test[0]\n",
    "# Getting array containing dataset labels\n",
    "y_train = train[1]\n",
    "y_test = test[1]\n",
    "# Normalize the values (pixels take values from 0 to 255, neural network works better with values from 0 to 1)\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data sample (for representations only)\n",
    "# index = int(input(f'Which data sample should be displayed (range from 0 to {len(x_train) - 1}): '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terminal representation of the sample digit from x_train dataset ('.' is being displayed when there is 0 in the dataset, otherwise 'o' is being displayed)\n",
    "def term_repr(index, labels, values):\n",
    "    print(labels[index], end = '\\n')\n",
    "    for m in range(len(values[index])):\n",
    "        for n in range(len(values[index][m])):\n",
    "            if (values[index][m][n] == 0.0):\n",
    "                print(f'.', end = ' ')\n",
    "            else:\n",
    "                print(f'o', end = ' ')\n",
    "        print(f'', end = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphical representation of the sample digit from x_train dataset\n",
    "def grap_repr(index, values):\n",
    "    fig = plt.figure()\n",
    "    fig.patch.set_facecolor((0, 0, 0))\n",
    "    plt.axis('off')\n",
    "    im = plt.imshow(values[index], cmap='Greys_r')\n",
    "    cbar = plt.colorbar(im)\n",
    "    cbar.set_label('Pixel value intensity [%]', color='#999', fontweight='bold', labelpad=20)\n",
    "    cbar.ax.tick_params(labelcolor='#999')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten train dataset\n",
    "def flatten(dataset, samples):\n",
    "    temp = np.zeros((samples, (dataset[0].shape[0] * dataset[0].shape[1])))\n",
    "    for m in range(samples):\n",
    "        for n in range(dataset[m].shape[0]):\n",
    "            for b in range(dataset[m].shape[1]):\n",
    "                temp[m][n * dataset[m].shape[0] + b] = dataset[m][n][b]\n",
    "    return np.transpose(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding of labels\n",
    "def one_hot(dataset, samples):\n",
    "    temp = np.zeros((10, samples))\n",
    "    for m in range(samples):\n",
    "        temp[dataset[m]][m] = 1\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter initialization\n",
    "def param_init(inputs, hiddens):\n",
    "    w1 = np.zeros((hiddens, inputs))\n",
    "    for m in range(len(w1)):\n",
    "        for n in range(len(w1[m])):\n",
    "            w1[m][n] = (rng.random() * 2) - 1\n",
    "    b1 = np.zeros((hiddens, 1))\n",
    "    return w1, b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward propagation\n",
    "def forward_propagation(sample, parameters):\n",
    "    # retrieve the parameters\n",
    "    w1, b1 = parameters\n",
    "    # compute the activation of the hidden layer\n",
    "    z1 = np.dot(w1, sample) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "    print(a1)\n",
    "    return a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean square error loss function\n",
    "def mean_square_error(a1, label, samples):\n",
    "    loss_arr = np.zeros((10, samples))\n",
    "    for m in range(len(a1)):\n",
    "        loss_arr[m] += ((a1[m] - label[m]) * (a1[m] - label[m]))\n",
    "    return loss_arr.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward propagation\n",
    "def backward_propagation(sample, label, parameters, a1, learning_rate):\n",
    "    # Retrieve parameters\n",
    "    w1, b1 = parameters\n",
    "    # Compute the gradient of the loss with respect to the hidden layer activation\n",
    "    dL_da1 = a1 - label\n",
    "    # Compute the gradient of the activation with respect to the linear combination (z1)\n",
    "    da1_dz1 = a1 * (1 - a1)\n",
    "    # Compute the gradient of the loss with respect to z1\n",
    "    dL_dz1 = dL_da1 * da1_dz1\n",
    "    # Compute the gradient of the loss with respect to w1 and b1\n",
    "    dL_dw1 = np.dot(dL_dz1, sample.T)\n",
    "    dL_db1 = np.sum(dL_dz1)\n",
    "    # Update the weights and biases \n",
    "    w1 -= dL_dw1 * learning_rate\n",
    "    b1 -= dL_db1 * learning_rate\n",
    "    return w1, b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the neural network\n",
    "def train(X, y, num_iterations, learning_rate):\n",
    "    samples = np.shape(X)[1]\n",
    "    # Initialize the weights and biases\n",
    "    parameters = param_init(784, 10)\n",
    "    for i in range(num_iterations):\n",
    "        # Forward propagation\n",
    "        a1 = forward_propagation(X, parameters)\n",
    "        # Compute the loss\n",
    "        loss = mean_square_error(a1, y, samples)\n",
    "        # Backward propagation\n",
    "        newparams = backward_propagation(X, y, parameters, a1, learning_rate)\n",
    "        # Update the parameters\n",
    "        parameters = newparams\n",
    "        # Display performance gain\n",
    "        print(f\"Iteration {i}: loss = {loss}\")\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_neural_network(X_test, y_test, parameters):\n",
    "    predictions = forward_propagation(X_test, parameters)\n",
    "    predicted_labels = np.argmax(predictions, axis=0)\n",
    "    actual_labels = np.argmax(y_test, axis=0)\n",
    "    accuracy = np.mean(predicted_labels == actual_labels)\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.19616014e-02]\n",
      " [9.13611667e-01]\n",
      " [7.38061586e-06]\n",
      " [9.98874043e-01]\n",
      " [9.96720327e-01]\n",
      " [9.99944931e-01]\n",
      " [9.95577430e-01]\n",
      " [6.26495505e-01]\n",
      " [8.30531070e-02]\n",
      " [4.82594753e-04]]\n",
      "Iteration 0: loss = 0.4217477677276674\n",
      "[[3.09708399e-02]\n",
      " [8.42424420e-01]\n",
      " [7.20934927e-06]\n",
      " [9.98835449e-01]\n",
      " [9.96541599e-01]\n",
      " [9.99943623e-01]\n",
      " [9.95288751e-01]\n",
      " [3.00389313e-01]\n",
      " [7.70709555e-02]\n",
      " [4.71400378e-04]]\n",
      "Iteration 1: loss = 0.378817910259429\n",
      "[[3.01545011e-02]\n",
      " [6.53796894e-01]\n",
      " [7.07321884e-06]\n",
      " [9.98800413e-01]\n",
      " [9.96363343e-01]\n",
      " [9.99942538e-01]\n",
      " [9.94990436e-01]\n",
      " [1.91362098e-01]\n",
      " [7.22943779e-02]\n",
      " [4.62502283e-04]]\n",
      "Iteration 2: loss = 0.34505539628651133\n",
      "[[2.93644064e-02]\n",
      " [3.24017105e-01]\n",
      " [6.93795055e-06]\n",
      " [9.98763627e-01]\n",
      " [9.96168875e-01]\n",
      " [9.99941418e-01]\n",
      " [9.94657847e-01]\n",
      " [1.50460179e-01]\n",
      " [6.81430902e-02]\n",
      " [4.53660452e-04]]\n",
      "Iteration 3: loss = 0.31123567513323225\n",
      "[[2.88496920e-02]\n",
      " [1.98731237e-01]\n",
      " [6.86501262e-06]\n",
      " [9.98736369e-01]\n",
      " [9.95992053e-01]\n",
      " [9.99940795e-01]\n",
      " [9.94335866e-01]\n",
      " [1.28168605e-01]\n",
      " [6.50300070e-02]\n",
      " [4.48892434e-04]]\n",
      "Iteration 4: loss = 0.30391610268167163\n",
      "[[2.84727382e-02]\n",
      " [1.55844377e-01]\n",
      " [6.82287761e-06]\n",
      " [9.98713870e-01]\n",
      " [9.95818871e-01]\n",
      " [9.99940430e-01]\n",
      " [9.94003754e-01]\n",
      " [1.13625207e-01]\n",
      " [6.25064051e-02]\n",
      " [4.46137681e-04]]\n",
      "Iteration 5: loss = 0.30190441884815344\n",
      "[[2.81434898e-02]\n",
      " [1.32211795e-01]\n",
      " [6.79037600e-06]\n",
      " [9.98692509e-01]\n",
      " [9.95637480e-01]\n",
      " [9.99940145e-01]\n",
      " [9.93642307e-01]\n",
      " [1.03072047e-01]\n",
      " [6.03029923e-02]\n",
      " [4.44012572e-04]]\n",
      "Iteration 6: loss = 0.3008538268331366\n",
      "[[2.78411808e-02]\n",
      " [1.16686550e-01]\n",
      " [6.76273427e-06]\n",
      " [9.98671460e-01]\n",
      " [9.95444027e-01]\n",
      " [9.99939900e-01]\n",
      " [9.93242297e-01]\n",
      " [9.49472495e-02]\n",
      " [5.83337301e-02]\n",
      " [4.42205112e-04]]\n",
      "Iteration 7: loss = 0.3001592643073263\n",
      "[[2.75570872e-02]\n",
      " [1.05484353e-01]\n",
      " [6.73799416e-06]\n",
      " [9.98650373e-01]\n",
      " [9.95235774e-01]\n",
      " [9.99939679e-01]\n",
      " [9.92794841e-01]\n",
      " [8.84370870e-02]\n",
      " [5.65506042e-02]\n",
      " [4.40587309e-04]]\n",
      "Iteration 8: loss = 0.2996344038242205\n",
      "[[2.72864874e-02]\n",
      " [9.69097301e-02]\n",
      " [6.71512062e-06]\n",
      " [9.98629051e-01]\n",
      " [9.95010099e-01]\n",
      " [9.99939474e-01]\n",
      " [9.92289658e-01]\n",
      " [8.30662428e-02]\n",
      " [5.49212123e-02]\n",
      " [4.39091512e-04]]\n",
      "Iteration 9: loss = 0.29919964284465894\n"
     ]
    }
   ],
   "source": [
    "# Train the neural network with the training data (using more samples for better training)\n",
    "train_samples = 1\n",
    "parameters = train(flatten(x_train, train_samples), one_hot(y_train, train_samples), 10, 0.1)\n",
    "# Test the neural network with the test data\n",
    "# test_samples = 100\n",
    "# test_neural_network(flatten(x_test, test_samples), one_hot(y_test, test_samples), parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
